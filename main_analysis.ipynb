{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), ('Data/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('dataset.csv',names=['Author','Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df['Author'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Text'] = data_df['Text'].map(lambda x: re.sub('\\r|\\n|\\'','',x))\n",
    "data_df['Text'] = data_df['Text'].map(lambda x: re.sub(r'--\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_df.head()\n",
    "#Generate corpus of words for use by the CountVectorizer\n",
    "corpus = []\n",
    "for text in data_df['Text']:\n",
    "    corpus.append(text)\n",
    "#corpus[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split the dataset based on attribute 'Author'.\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = data_df.pop(\"Author\")\n",
    "#X = data_df\n",
    "#print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df['Text'], y, test_size=0.3, stratify=y,random_state=42) \n",
    "#print((X_train['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both test and train labels contain instances of all the 50 authors. \n",
    "df_ytrain = pd.DataFrame(y_train)\n",
    "df_ytest = pd.DataFrame(y_test)\n",
    "print(len(df_ytrain['Author'].value_counts()))\n",
    "print(len(df_ytest['Author'].value_counts()))\n",
    "type(df_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words removal\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#remove punctuations\n",
    "X_train = X_train.str.replace(\"[^\\w\\s]\", \"\")\n",
    "X_test = X_test.str.replace(\"[^\\w\\s]\", \"\")\n",
    "\n",
    "#remove stop words\n",
    "X_train = X_train.apply((lambda x: ' '.join([word for word in x.split() if word not in (stop)])))\n",
    "X_test = X_test.apply((lambda x: ' '.join([word for word in x.split() if word not in (stop)])))\n",
    "#print((X_train.head(1)))\n",
    "#print(X_test.head(1))\n",
    "#i=1\n",
    "#for row in X_train:\n",
    "#    print(row)\n",
    "#    if i == 1:\n",
    "#        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <3500x3561 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 520017 stored elements in Compressed Sparse Row format>>\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "  (0, 2025)\t1\n",
      "  (0, 3056)\t1\n",
      "  (0, 3270)\t1\n",
      "  (0, 3046)\t1\n",
      "  (0, 318)\t1\n",
      "  (0, 2021)\t1\n",
      "  (0, 2113)\t1\n",
      "  (0, 2961)\t1\n",
      "  (0, 2374)\t1\n",
      "  (0, 3476)\t1\n",
      "  (0, 2816)\t1\n",
      "  (0, 112)\t1\n",
      "  (0, 1821)\t1\n",
      "  (0, 3240)\t1\n",
      "  (0, 1176)\t1\n",
      "  (0, 3481)\t1\n",
      "  (0, 158)\t1\n",
      "  (0, 1954)\t1\n",
      "  (0, 1286)\t1\n",
      "  (0, 775)\t1\n",
      "  (0, 696)\t1\n",
      "  (0, 1982)\t1\n",
      "  (0, 2660)\t1\n",
      "  (0, 2188)\t1\n",
      "  (0, 1907)\t1\n",
      "  :\t:\n",
      "  (3499, 839)\t1\n",
      "  (3499, 1670)\t1\n",
      "  (3499, 48)\t1\n",
      "  (3499, 2868)\t1\n",
      "  (3499, 1542)\t1\n",
      "  (3499, 1171)\t1\n",
      "  (3499, 998)\t1\n",
      "  (3499, 2314)\t1\n",
      "  (3499, 3226)\t1\n",
      "  (3499, 1930)\t1\n",
      "  (3499, 347)\t2\n",
      "  (3499, 915)\t1\n",
      "  (3499, 2741)\t1\n",
      "  (3499, 1202)\t1\n",
      "  (3499, 357)\t1\n",
      "  (3499, 78)\t1\n",
      "  (3499, 1369)\t1\n",
      "  (3499, 1989)\t1\n",
      "  (3499, 647)\t1\n",
      "  (3499, 3495)\t1\n",
      "  (3499, 3046)\t1\n",
      "  (3499, 2374)\t1\n",
      "  (3499, 1657)\t1\n",
      "  (3499, 2574)\t1\n",
      "  (3499, 977)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word',max_df=0.50,min_df=0.01)\n",
    "#count_vect.fit(corpus)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "Xtrain_count =  count_vect.fit_transform(X_train)\n",
    "Xtest_count =  count_vect.transform(X_test)\n",
    "\n",
    "#print(count_vect.get_feature_names())\n",
    "\n",
    "print(Xtrain_count.__str__)\n",
    "print(Xtrain_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method spmatrix.__str__ of <3500x886 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 63980 stored elements in Compressed Sparse Row format>>\n",
      "  (0, 334)\t0.15120287306396993\n",
      "  (0, 493)\t0.15819676836011215\n",
      "  (0, 813)\t0.16815733131096924\n",
      "  (0, 133)\t0.28108830006372765\n",
      "  (0, 838)\t0.1799954814808407\n",
      "  (0, 304)\t0.1377453624650417\n",
      "  (0, 144)\t0.28197329585488445\n",
      "  (0, 170)\t0.18420240924838607\n",
      "  (0, 808)\t0.16601527811112568\n",
      "  (0, 309)\t0.15659692589985375\n",
      "  (0, 492)\t0.15544570165165714\n",
      "  (0, 97)\t0.16653797088191252\n",
      "  (0, 527)\t0.16653797088191252\n",
      "  (0, 237)\t0.17556353383454715\n",
      "  (0, 246)\t0.1692825341505534\n",
      "  (0, 651)\t0.14326982924075973\n",
      "  (0, 15)\t0.16601527811112568\n",
      "  (0, 147)\t0.18079528656714403\n",
      "  (0, 134)\t0.16601527811112568\n",
      "  (0, 775)\t0.13708810722557516\n",
      "  (0, 21)\t0.1742086393863196\n",
      "  (0, 302)\t0.14051282349587751\n",
      "  (0, 411)\t0.10310118762872844\n",
      "  (0, 539)\t0.12869873298997017\n",
      "  (0, 410)\t0.17487917340371287\n",
      "  :\t:\n",
      "  (3498, 749)\t0.14912587653345552\n",
      "  (3498, 26)\t0.15549231665033894\n",
      "  (3498, 518)\t0.1684699498515044\n",
      "  (3498, 70)\t0.1643319711096728\n",
      "  (3498, 80)\t0.19583204833157766\n",
      "  (3498, 519)\t0.17090000337637587\n",
      "  (3498, 71)\t0.16650399261433987\n",
      "  (3498, 29)\t0.19870133767665474\n",
      "  (3498, 668)\t0.15340004340394367\n",
      "  (3498, 475)\t0.17754251234261023\n",
      "  (3498, 16)\t0.18612886609654544\n",
      "  (3498, 368)\t0.1674742588851232\n",
      "  (3498, 67)\t0.20345754100393845\n",
      "  (3498, 567)\t0.20793330002424623\n",
      "  (3498, 299)\t0.1481284431257727\n",
      "  (3498, 721)\t0.16403157404239616\n",
      "  (3498, 591)\t0.19945383813016013\n",
      "  (3498, 623)\t0.20793330002424623\n",
      "  (3498, 843)\t0.17466546076052944\n",
      "  (3498, 352)\t0.20889537751553022\n",
      "  (3498, 832)\t0.21193700289802456\n",
      "  (3498, 505)\t0.1850732417959866\n",
      "  (3498, 118)\t0.18776940997092564\n",
      "  (3499, 716)\t0.7503944951585833\n",
      "  (3499, 351)\t0.6609902432227687\n"
     ]
    }
   ],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word',sublinear_tf=True, max_df=0.50,min_df=0.01)\n",
    "#tfidf_vect.fit(corpus)\n",
    "Xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "Xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "#print(Xtrain_tfidf.__str__)\n",
    "#print(Xtrain_tfidf)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3),sublinear_tf=True, max_df=0.50,min_df=0.01)\n",
    "#tfidf_vect_ngram.fit(corpus)\n",
    "Xtrain_tfidf_ngram = tfidf_vect_ngram.fit_transform(X_train)\n",
    "Xtest_tfidf_ngram = tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "print(Xtrain_tfidf_ngram.__str__)\n",
    "print(Xtrain_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_test, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 3561)\n",
      "NB, Count Vectors:  0.788\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_tfidf.shape)\n",
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), Xtrain_count, y_train, Xtest_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF:  0.7553333333333333\n",
      "NB, N-Gram Vectors:  0.6593333333333333\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), Xtrain_tfidf, y_train, Xtest_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), Xtrain_tfidf_ngram, y_train, Xtest_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.5553333333333333\n"
     ]
    }
   ],
   "source": [
    "# SVM on Ngram Level TF IDF Vectors\n",
    "\n",
    "accuracy = train_model(svm.SVC(), Xtrain_tfidf_ngram, y_train, Xtest_tfidf_ngram)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
